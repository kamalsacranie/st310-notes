% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{report}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={ST310 - Machine Learning},
  pdfauthor={Kamal Sacranie},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[a4paper,margin=3cm]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{48,48,48}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.81,0.69}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.50,0.62,0.50}{\textbf{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.80,0.80,0.80}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.86,0.64,0.64}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.80,0.80,0.80}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.86,0.64,0.64}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.50,0.62,0.50}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.50,0.62,0.50}{\textbf{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.86,0.64,0.64}{\textbf{#1}}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.94,0.87,0.69}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.87,0.87,0.75}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.86,0.86,0.80}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.50,0.62,0.50}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.76,0.75,0.62}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.80,0.80,0.80}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.75,0.75,0.82}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.94,0.94,0.56}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.80,0.80,0.80}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.50,0.62,0.50}{\textbf{#1}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.94,0.87,0.69}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.80,0.80,0.80}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.94,0.94,0.82}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.94,0.94,0.56}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{1.00,0.81,0.69}{\textbf{#1}}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.80,0.80,0.80}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.86,0.64,0.64}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.80,0.58,0.58}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.80,0.58,0.58}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.80,0.80,0.80}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.80,0.58,0.58}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.50,0.62,0.50}{\textbf{#1}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Importing our necessary packages
\usepackage{booktabs}
% Footnotes fixed to bottom
\usepackage[bottom]{footmisc}
\usepackage{multicol}
\usepackage[edges]{forest}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{cancel}
% Setting our text to not bet justified across the whole page and no hyphen
\usepackage[document]{ragged2e}
\usepackage[none]{hyphenat}

% Importing our tikz
\usetikzlibrary{trees}
\usetikzlibrary{backgrounds}

% Setting our mono code to use fira code
\usepackage{fontspec}
\setmonofont[
	Contextuals={Alternate}
]{Hasklug Nerd Font Mono}

% Setting up our hyperlinks
\hypersetup{colorlinks = true, linkcolor = blue, urlcolor = blue}

% Changing chaper text
\renewcommand{\chaptername}{Chapter}
% Chaning padding between footnote line and text
\addtolength{\skip\footins}{1em}
% % Change space between bullets
% \renewcommand{\tightlist}{
% \setlength{\itemsep}{0.4em}
% \setlength{\topsep}{1cm}
% \setlength{\partopsep}{1cm}
% }
% Decreasing space before chapter title
\titleformat{\chapter}[display]{\normalfont\Large\bfseries}{\chaptertitlename\ \thechapter}{0pt}{\huge}
\titlespacing*{\chapter}{10pt}{0pt}{20pt}

% Making the repositioning of our images more forgiving
\renewcommand{\topfraction}{.85}
\renewcommand{\bottomfraction}{.7}
\renewcommand{\textfraction}{.15}
\renewcommand{\floatpagefraction}{.66}
\setcounter{topnumber}{3}
\setcounter{bottomnumber}{3}
\setcounter{totalnumber}{4}

% Creating shaded indented box for quote
\usepackage{xcolor}
\usepackage[framemethod=TikZ]{mdframed}

\colorlet{quoteshadecolor}{yellow!10!white}
\renewenvironment{quote}{
	\bigskip\begin{mdframed}[
			skipabove=\topskip,
			skipbelow=\topskip,
			backgroundcolor=quoteshadecolor,
			leftmargin=0.5cm,
			rightmargin=0.5cm,
			topline=false,
			rightline=false,
			bottomline=false,
			nobreak=true,
		]\itshape%itemshape is for italics
		}{
	\end{mdframed}
}


% Changing the background color of our code blocks
% \colorlet{shadecolor}{magenta!20!white}
% \definecolor{code}{RGB}{178,178,178}
% Defining our shadecolor (used fo shading code blocks usually)
\definecolor{code}{RGB}{1,22,80} % This is how you define a color in latex
\colorlet{shadecolor}{code} % redefining our shadecolor to be code color
% Using tcolorbox to make a background box
\usepackage[many]{tcolorbox}
\tcbset{enhanced,colback=red!5!white,
	colframe=red!75!black,fonttitle=\bfseries}
% Renewing the shaded environemnt with new mdframed box
\renewenvironment{Shaded}{
	\bigskip
	\begin{tcolorbox}[drop fuzzy midday shadow]
		\begin{mdframed}[
				skipabove=\topskip*2,
				outerlinewidth= 0,
				linewidth=0pt,
				roundcorner= 3pt,
				backgroundcolor= shadecolor,
				outerlinecolor= shadecolor,
				innertopmargin= \topskip,
				innerbottommargin=\topskip,
				leftmargin=-0.8cm,
				rightmargin=-0.8cm
			]}{
		\end{mdframed}
	\end{tcolorbox}
	\smallskip
}

% fancyhdr for header and footer
\usepackage{fancyhdr}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{Kamal Sacranie}
\fancyhead[RE,LO]{Chapter \thechapter}
\fancyfoot[C]{\thepage}

\renewcommand{\headrulewidth}{2pt}
\renewcommand{\footrulewidth}{0pt}



\renewenvironment{example}{
	\begin{tcolorbox}[drop fuzzy midday shadow]
		}{
	\end{tcolorbox}
}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{ST310 - Machine Learning}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Machine Learning course using R with Joshua Loftus}
\author{Kamal Sacranie}
\date{January 24, 2022}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\newtheorem{conjecture}{Conjecture}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\theoremstyle{definition}
\newtheorem{hypothesis}{Hypothesis}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}
\addcontentsline{toc}{chapter}{Preface}

The main readings used in this course are:

\begin{itemize}
\tightlist
\item
  \textbf{ISLR} \href{https://statlearning.com/}{Introduction to Statistical Learning}
\item
  \textbf{ESL} \href{https://web.stanford.edu/~hastie/ElemStatLearn/}{Elements of Statistical Learning}
\item
  \textbf{CASI} \href{https://web.stanford.edu/~hastie/CASI/}{Computer Age Statistical Inference}
\item
  \textbf{Mixtape} \href{https://mixtape.scunning.com/index.html}{Causal Inference: The Mixtape}
\item
  \textbf{R4DS} \href{https://r4ds.had.co.nz/}{R for Data Science}
\end{itemize}

\begin{quote}
In this course the textbook readings are required readings but the lecture
video emphasise themes that complement the textbook
\end{quote}

I Like this guy. I wish I had taken this course for real lol :(

\hypertarget{r-package-list}{%
\section{\texorpdfstring{\texttt{R} package list}{R package list}}\label{r-package-list}}

\begin{itemize}
\tightlist
\item
  \texttt{tidyverse}: just a bunch of commonly used packages
\item
  \texttt{gapminder}: just some random datasets we can use
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{library}\NormalTok{(gapminder)}
\FunctionTok{library}\NormalTok{(fivethirtyeight)}
\FunctionTok{library}\NormalTok{(broom)}
\FunctionTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

\hypertarget{part-week-1}{%
\part{Week 1}\label{part-week-1}}

\hypertarget{simple-plotting-with-ggplot}{%
\chapter{\texorpdfstring{Simple plotting with \texttt{ggplot}}{Simple plotting with ggplot}}\label{simple-plotting-with-ggplot}}

What is the association between GDP and life-expectancy:

\hypertarget{using-ggplot}{%
\section{\texorpdfstring{Using \texttt{ggplot}}{Using ggplot}}\label{using-ggplot}}

\begin{example}[GDP vs life expectancy]
\protect\hypertarget{exm:gdp-life-exp}{}\label{exm:gdp-life-exp}

\hfill\break

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{ggplot}\NormalTok{(}
  \CommentTok{\# Piping to mutate to boolean index the data}
\NormalTok{  gapminder }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}
    \CommentTok{\# Simple boolean logic here and passing it as a kwarg to the mutate}
    \CommentTok{\# function}
    \AttributeTok{indicator =}\NormalTok{ (country }\SpecialCharTok{==} \StringTok{"United Kingdom"}\NormalTok{)}
\NormalTok{  ),}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ gdpPercap, }\AttributeTok{y =}\NormalTok{ lifeExp)}
\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\# How the fuck has indicator now got local scope. Was it created by the}
  \CommentTok{\# mutate fucntion. But even then? it\textquotesingle{}s not returning anything, where is}
  \CommentTok{\# idnicator being assigned}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{color =}\NormalTok{ indicator))}
\end{Highlighting}
\end{Shaded}

\end{example}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{itemize}
\tightlist
\item
  \texttt{aes} stands for aesthetic and creates an aesthetic mapping between our
  dataset and the aesthetic properties of the plot. It's a function which is
  passed as an in place arg called a \texttt{mapping} function
\item
  \texttt{aes} takes an x variable and y variable form our dataset as arguments
\item
  \texttt{geom\_point} is one of the many plots that come with \texttt{ggplot} and plots a
  point plot
\end{itemize}

\begin{quote}
The \texttt{aes} argument which goes in the first \texttt{ggplot} function applier for the
whole ``canvas'', whereas the ones for the secondary functions only apply to
that specific function. So \textbf{if you want to apply colour to only the
regression line, you do the \texttt{aes} in the \texttt{geom\_smooth} function}
\end{quote}

In the above example we use the \texttt{\%\textgreater{}\%} operator (provided by the package dyplr).

This is maybe the only good thing about R that I have encoutered. It works
similarly to the pipe character in bash. It takes the return from the last
function pipes it into the first argument of the next function.

\begin{quote}
For the record, it is insanely retarded that we can just pass through the
columns of \texttt{gapminder} as if they were variables. We haven't assigned them or
anything. It's also insane to me that we use ggplot and then ADD A PLOT?? WTF
does that even mean. Why are these two objects able to be added. How is there
not a type error
\end{quote}

\hypertarget{the-pipe}{%
\section{\texorpdfstring{The pipe \texttt{\%\textgreater{}\%}}{The pipe \%\textgreater\%}}\label{the-pipe}}

As previously mentioned\ldots{} the only good thing about \texttt{R}. Just plugs the data
into the first argument of the next function.

\begin{example}[Piping to a function]
\protect\hypertarget{exm:pipe-vs-normal}{}\label{exm:pipe-vs-normal}

\hfill\break

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{gapminder }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{nrow}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

is the same as

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{nrow}\NormalTok{(gapminder)}
\end{Highlighting}
\end{Shaded}

\end{example}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

This is often what \texttt{R} uses to stack things. It's basically becasue \texttt{R} is made
by people who are too retarded to read regular nested code or even just regular
lines of code.

\hypertarget{filtering-for-a-value-in-column-basically-boolean-indexing}{%
\section{Filtering for a value in column (basically boolean indexing)}\label{filtering-for-a-value-in-column-basically-boolean-indexing}}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{\# notice that we can pass a straight int here. R knows the type in the column}
\NormalTok{base\_plot }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}
  \CommentTok{\# Easier to see here that mutate basically adds a column with a boolean value}
  \CommentTok{\# showing whether it\textquotesingle{}s the UK or not}
  \FunctionTok{filter}\NormalTok{(gapminder, year }\SpecialCharTok{==} \DecValTok{2007}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{indicator =}\NormalTok{ (country }\SpecialCharTok{==} \StringTok{"United Kingdom"}\NormalTok{)),}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ gdpPercap, }\AttributeTok{y =}\NormalTok{ lifeExp)}
\NormalTok{) }\SpecialCharTok{+} \CommentTok{\# The plus is similar to the pipe, it is introduces by ggplot and basically}
  \CommentTok{\# allows you to build layers on your plot}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{color =}\NormalTok{ indicator))}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  The \texttt{+} is like ggplot's version of the pipe. It's used to layer graphs
\item
  \texttt{indicator} is accessable because it's a column of our \texttt{gapminder} data which
  is being pushed through with our plus
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{base\_plot }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  The line curves around the points and fits locally to the points
\item
  The gray area is the confidence intreval of the fit line
\end{itemize}

\hypertarget{model-objects}{%
\section{Model objects}\label{model-objects}}

Everything is an object in \texttt{R} and our assignment operator is \texttt{\textless{}-}:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{gm\_2007 }\OtherTok{\textless{}{-}}\NormalTok{ gapminder }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{==} \DecValTok{2007}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Great so we can use that everywhere in this \texttt{R} file. For example, we can use
the \texttt{lm} function for fitting models

\begin{example}[A basic model function use]
\protect\hypertarget{exm:lm-basic-fit}{}\label{exm:lm-basic-fit}

\hfill\break

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{gm\_lm }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(lifeExp }\SpecialCharTok{\textasciitilde{}}\NormalTok{ gdpPercap, }\AttributeTok{data =}\NormalTok{ gm\_2007)}
\end{Highlighting}
\end{Shaded}

\end{example}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{quote}
A common way for model funciton to work in \texttt{R} is to require the assignment
of the lefthand side and the right hand side variables; we see this in
\ref{exm:lm-basic-fit} with the use of the \texttt{\textasciitilde{}}. On the left of the tilde we
have the dependent (outcome) variable and on the right we have the
independent (predictor) variable
\end{quote}

In \ref{exm:lm-basic-fit} \texttt{lm} stands for linear model (a regression) and is
an object which contains all the information for our regression. When you print
it on its ones, there isn't much you can do

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{summary}\NormalTok{(gm\_lm)}
\FunctionTok{residuals}\NormalTok{(gm\_lm) }\CommentTok{\# the difference in the predicted values and the actual}
\FunctionTok{predict}\NormalTok{(gm\_lm)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  \texttt{summary} is a builtin function which displays a summary \textbf{of any model
  object in \texttt{R}}
\item
  This also shows us standard errors, p-values, etc.
\end{itemize}

\begin{quote}
Something I find weird here is that all the data we need is inside the \texttt{lm}
object but instead of using a method to produce the result like I would
expect, we have to pass it to another function
\end{quote}

\hypertarget{broom}{%
\section{\texorpdfstring{\texttt{broom}}{broom}}\label{broom}}

\texttt{broom} is just a library that provides nice out of the box rendering for \texttt{R}'s
model objects.

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{library}\NormalTok{(broom)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{tidy}\NormalTok{(gm\_lm)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  The \texttt{broom::tidy} function is really nice for making tables look good
\item
  Don't think it works in latex though
\end{itemize}

We also have the \texttt{broom::glance} function which shows our most important values
at a glance. You can also compare two models with it:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{glance}\NormalTok{(gm\_lm)}
\end{Highlighting}
\end{Shaded}

The last main fucntion from \texttt{broom} is \texttt{augment}. This gives us the original
dataset back plus the extra rows like standard errors for residuals, residuals,
etc. This function is really useful for plotting the results of the model

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{augment}\NormalTok{(gm\_lm) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ gdpPercap, }\AttributeTok{y =}\NormalTok{ lifeExp)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \CommentTok{\# the geom line adds a line to the plot on top of the already existing plot,}
  \CommentTok{\# i.e. we can give it a different x and y to plot via the aes which returns a}
  \CommentTok{\# mapping}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ gdpPercap, }\AttributeTok{y =}\NormalTok{ .fitted))}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Note here how ggplot basically crease the canvas for the plot. Then you layer
  on a point distribution using the data, then you layer on a line using the
  data and specifying the variable you want. In this case \texttt{.fitted} will give
  us all the points on the fitted line. This is the same as using ggplot's
  \texttt{geom\_smooth} function. We are just doing it the long way around
\end{itemize}

\hypertarget{subbing-out-function-for-e.g.-loess}{%
\section{\texorpdfstring{Subbing out function for e.g.~\texttt{loess}}{Subbing out function for e.g.~loess}}\label{subbing-out-function-for-e.g.-loess}}

The most important takeaway here is the idea of \textbf{model flexibility}. We have
made a robust programme which let's us swap in and out functions. For example,
let's use the \texttt{loess} function to plot the local extimation line which is the
default given by ggplot's \texttt{geom\_smooth}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{gm\_loess }\OtherTok{\textless{}{-}} \FunctionTok{loess}\NormalTok{(lifeExp }\SpecialCharTok{\textasciitilde{}}\NormalTok{ gdpPercap, }\AttributeTok{data =}\NormalTok{ gm\_2007, }\AttributeTok{span =}\NormalTok{ .}\DecValTok{5}\NormalTok{)}
\FunctionTok{summary}\NormalTok{(gm\_loess)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Again, we see the tilde notation for specifying LHS and RHS
\item
  An interesting note. When I ran what I thought was known as the \texttt{tidy}
  \textbf{function}, \texttt{R} threw an error mentioning loess object doesn't have the
  method \texttt{tidy}. I.e. methods are defined in objects but somehow they are
  called with function notation.
\end{itemize}

\begin{example}[loess example]
\protect\hypertarget{exm:loess}{}\label{exm:loess}

\hfill\break

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{augment}\NormalTok{(gm\_loess) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(gdpPercap, lifeExp)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(gdpPercap, .fitted))}
\end{Highlighting}
\end{Shaded}

\end{example}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{what-is-loess-actaully-doing}{%
\subsection{\texorpdfstring{What is \texttt{loess} actaully doing}{What is loess actaully doing}}\label{what-is-loess-actaully-doing}}

\texttt{loess} stands for ``locally estimated scatter-plot smoothing''. If we look at
the output of exmaple \ref{exm:loess}, we see that it is looking at the local
points and approximating them. \texttt{loess} has some options, for example:

\begin{itemize}
\tightlist
\item
  \texttt{span}: tells the function how localised to make its approximation
\end{itemize}

\hypertarget{candy-rankings}{%
\chapter{Candy rankings}\label{candy-rankings}}

It's always good practice to start by visualising some of your data. For fun
let's just fit a simple linear model to this dataset:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{cr\_lm }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(pricepercent }\SpecialCharTok{\textasciitilde{}}\NormalTok{ winpercent, }\AttributeTok{data =}\NormalTok{ candy\_rankings)}
\FunctionTok{tidy}\NormalTok{(cr\_lm)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{augment}\NormalTok{(cr\_lm) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ pricepercent, }\AttributeTok{y =}\NormalTok{ winpercent)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ .fitted))}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Nice tip with \texttt{geom} functions is that because it take in the object the
  previous function returns, you can keep the \texttt{x} value the same and reassign
  the \texttt{y}
\end{itemize}

\hypertarget{adding-a-categorical-variable-to-our-model}{%
\section{Adding a categorical variable to our model}\label{adding-a-categorical-variable-to-our-model}}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{cr\_lm\_cat }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(winpercent }\SpecialCharTok{\textasciitilde{}}\NormalTok{ pricepercent }\SpecialCharTok{+}\NormalTok{ chocolate, candy\_rankings)}
\FunctionTok{tidy}\NormalTok{(cr\_lm\_cat)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Here in the \texttt{formula} argument, we add the categorical variable \texttt{chocolate}
\item
  This becomes a dummy variable for our regression model (\texttt{chocolateTRUE})
\end{itemize}

Let's now represent this new categorical variable on our plot through the use
of colour:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{augment}\NormalTok{(cr\_lm\_cat) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ pricepercent,}
    \AttributeTok{y =}\NormalTok{ winpercent,}
    \AttributeTok{color =}\NormalTok{ chocolate,}
    \AttributeTok{shape =}\NormalTok{ chocolate,}
    \AttributeTok{linetype =}\NormalTok{ chocolate}
\NormalTok{  )) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ .fitted))}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  So in the \texttt{aes} function we have a whole load of arguments which take a set
  of true or false values to boolean index the characteristics of the data
\end{itemize}

\hypertarget{adding-a-continuous-predictor-and-creating-a-3d-plot}{%
\section{Adding a continuous predictor and creating a 3D plot}\label{adding-a-continuous-predictor-and-creating-a-3d-plot}}

A common package used to create 3D plots is \texttt{plotly}.

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{candy3d }\OtherTok{\textless{}{-}}\NormalTok{ plotly}\SpecialCharTok{::}\FunctionTok{plot\_ly}\NormalTok{(candy\_rankings,}
  \AttributeTok{x =} \SpecialCharTok{\textasciitilde{}}\NormalTok{pricepercent, }\AttributeTok{y =} \SpecialCharTok{\textasciitilde{}}\NormalTok{sugarpercent,}
  \AttributeTok{z =} \SpecialCharTok{\textasciitilde{}}\NormalTok{winpercent,}
  \AttributeTok{type =} \StringTok{"scatter3d"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
This is a perfect example of how \texttt{R} is so good out the box for data
visualisation
\end{quote}

We can fit our regression plane in this three dimensional space:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{cr\_lm\_sugar }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(}
\NormalTok{  winpercent }\SpecialCharTok{\textasciitilde{}}\NormalTok{ pricepercent }\SpecialCharTok{+}\NormalTok{ sugarpercent,}
  \AttributeTok{data =}\NormalTok{ candy\_rankings}
\NormalTok{)}

\NormalTok{xy\_plane }\OtherTok{\textless{}{-}} \FunctionTok{expand.grid}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{100}\NormalTok{, }\DecValTok{0}\SpecialCharTok{:}\DecValTok{100}\NormalTok{) }\SpecialCharTok{/} \DecValTok{100}
\NormalTok{ps\_plane }\OtherTok{\textless{}{-}}\NormalTok{ xy\_plane }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{pricepercent =}\NormalTok{ Var1, }\AttributeTok{sugarpercent =}\NormalTok{ Var2)}

\NormalTok{lm\_plane }\OtherTok{\textless{}{-}} \FunctionTok{augment}\NormalTok{(cr\_lm\_sugar, }\AttributeTok{newdata =}\NormalTok{ ps\_plane)}
\NormalTok{lm\_matrix }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(lm\_plane}\SpecialCharTok{$}\NormalTok{.fitted, }\AttributeTok{nrow =} \DecValTok{101}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{101}\NormalTok{)}

\NormalTok{candy3d }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_surface}\NormalTok{(}
    \AttributeTok{x =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ (}\DecValTok{0}\SpecialCharTok{:}\DecValTok{100}\NormalTok{) }\SpecialCharTok{/} \DecValTok{100}\NormalTok{,}
    \AttributeTok{y =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ (}\DecValTok{0}\SpecialCharTok{:}\DecValTok{100}\NormalTok{) }\SpecialCharTok{/} \DecValTok{100}\NormalTok{,}
    \AttributeTok{z =} \SpecialCharTok{\textasciitilde{}}\NormalTok{lm\_matrix}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  The \texttt{expand.grid} function creates a data frame from all combinations of the
  supplied vectors or factors
\item
  We then rename the variable of the plane with \texttt{rename}
\item
  We then see the \texttt{augment} function in use
\end{itemize}

\hypertarget{machine-learning-applications}{%
\chapter{Machine learning applications}\label{machine-learning-applications}}

Some examples of machine learning are:

\begin{itemize}
\tightlist
\item
  Scraping social-media to predict period of unrest before it happens
\item
  Using health records to predict which patients will require more care
\item
  Algorithms which collect data to adapt
\end{itemize}

Basically any predictive model that uses data to predict the future. In this
course we focus on the underlying theory of how the methods function.

\begin{quote}
The difference between AI and ML, is that AI allows us to get mathematical
relationships from data that is unstructure, non-mathematical. This could be
images etc. Contrasting this with what we did in section
\ref{simple-plotting-with-ggplot} where our inputs were very mathematical
and numerical. In this course \textbf{when we refer to data, we are already talking
about vectorised, structured data}
\end{quote}

\hypertarget{abstraction-and-notation}{%
\section{Abstraction and notation}\label{abstraction-and-notation}}

In an abstract sense, the data we look at is formatted as a collection of \(p\)
district \textbf{variables}\footnote{Think columns of your data}:

\begin{align*}
  X = (X_1, X_2, \ldots, X_p) \in \mathbb{R^{p}}
\end{align*}

\begin{itemize}
\tightlist
\item
  We assume each \textbf{observation is a point in the vectors space}
  \(\mathbb{R^{p}}\)
\item
  We also assume that \(p\) is finite
\end{itemize}

\textbf{Supervised learning}: if we think of an application for ML which has a clear
\(Y\) variable defined, i.e.~the outcomes\footnote{Sometimes called responsive} of the
model, the we are dealing with supervised learning.

\textbf{Unsupervised learning}: if there is no natural outcome variable \(Y\), then we
are dealing with unsupervised learning. This is where you try and create a
mathematical relationship out of unstructured data.

\hypertarget{sub-categories-of-supervised-ml}{%
\subsection{Sub categories of supervised ML}\label{sub-categories-of-supervised-ml}}

Common cases:

\begin{itemize}
\tightlist
\item
  If \(Y\) is numeric: \textbf{regression}
\item
  If \(Y\) is categorical: \textbf{classification}
\end{itemize}

Special cases:

\begin{itemize}
\tightlist
\item
  \(Y\) is binary with rare cases, e.g.~anomaly detection
\item
  \(Y\) is a time to event, survival analysis
\item
  Multi-class, hierarchical classes, etc
\end{itemize}

\hypertarget{how-to-predict-y-from-x}{%
\section{\texorpdfstring{How to predict \(Y\) from \(X\)}{How to predict Y from X}}\label{how-to-predict-y-from-x}}

\begin{itemize}
\tightlist
\item
  We want to estimate \(\exists f\) such that the graph of the function \(y = f(x)\) fit the data perfectly\footnote{Fundamental idea of regression}
\item
  \textbf{Problem}: what if \((x_1, y_1) = (1, 0)\) and \((x_2, y_2) = (1, 1)\)?
\item
  \textbf{Problem}: even our most tested and verified physical laws won't fit data
  perfectly
\end{itemize}

Even if we are thinking about cases where our data is supposed to follow a
well-defined law, upon measuring we will often see that this doesn't quite
work.\\
The \textbf{solution} to this problem is to have an error term. For any function
\(f\), we can always get the residuals:

\begin{align*}
  \epsilon\equiv y - f(x)
\end{align*}

\begin{itemize}
\tightlist
\item
  \(y\) is the actual observation and we deduct the predicted value to see our
  residual (error)
\end{itemize}

\textbf{\emph{We want a function which minimises error.}}

The simplest way to minimise this error is to find out which function decreases
our squared error\footnote{This is premised on the fact that \(\epsilon\) has some sort
  of probability distribution so we can predict it}. A good function is defined
as:

\begin{align*}
  \mathbb{E}[\epsilon^2] = \mathbb{E}\{[Y - f(X)]^2\}
\end{align*}

This motivates the \textbf{plug-in principle}: compute an \emph{estimate} \(\hat{f}\) of
the good function \(f\) by solving the corresponding problem on the dataset,
i.e.:

\begin{align*}
  \min\sum_{i = 1}^{n}\left[y_{i} - \hat{f}(s_{i})\right]^{2}
\end{align*}

\begin{quote}
Basically, there is this perfect function out there \(f\). It is almost
impossible to arrive at that function so we have to calculate \(\hat{f}\) which
minimises our error and approximates our perfect function.
\end{quote}

\hypertarget{bias-variance-trade-off}{%
\section{Bias-variance trade-off}\label{bias-variance-trade-off}}

Errors that are systematic are bias in the system. The bias-variance trade-off
is formally described as follows:

\begin{equation}
  \mathbb{E}\{[Y - \hat{f}(X)]^{2}\} = \text{Var}(\hat{f}) +
  \text{Bias}(\hat{f})^{2} \label{eq:bias-var-to}
\end{equation}

\begin{itemize}
\tightlist
\item
  The expected error of our function is a combination of bias and variance
\end{itemize}

Combining this idea of BV trad-off with our idea of model complexity, we
typically see that \textbf{more complex models have lower bias and higher variance}.

Typical there is a sweet spot for complexity

Figure \ref{fig:complexity-variance} shows us a great preview between a more
complex model which visually even has more variance and a less complex model
which doesn't deviate too much but as such has more bias.

\begin{figure}

{\centering \includegraphics[width=0.4\linewidth]{./assets/03-machine-learning-applications/img/2022-01-23-02-58-55} \includegraphics[width=0.4\linewidth]{./assets/03-machine-learning-applications/img/2022-01-23-02-59-17} 

}

\caption{complexity-variance}\label{fig:complexity-variance}
\end{figure}

\begin{itemize}
\tightlist
\item
  It is difficult to tell visually which model is better
\end{itemize}

\hypertarget{evaluation-mean-squared-error}{%
\section{Evaluation: mean squared error}\label{evaluation-mean-squared-error}}

It is extremely easy to evaluate MSE in \texttt{R}. You use the \texttt{residuals} function
which takes a \texttt{model} object as an argument:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{c}\NormalTok{(}
  \FunctionTok{mean}\NormalTok{(}\FunctionTok{residuals}\NormalTok{(gm\_simple)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{),}
  \FunctionTok{mean}\NormalTok{(}\FunctionTok{residuals}\NormalTok{(gm\_complex)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\texttt{candy\_rankings} models:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{c}\NormalTok{(}
  \FunctionTok{mean}\NormalTok{(}\FunctionTok{residuals}\NormalTok{(candy\_simple)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{),}
  \FunctionTok{mean}\NormalTok{(}\FunctionTok{residuals}\NormalTok{(candy\_complex)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  These variables we are passing through are object from a model function like
  \texttt{lm}
\item
  The above results would show us that the more complex models have lower MSE.
  This is mostly true because your function better approximates the data. But
  this is where the question of overfitting comes into play because if we use
  that same function on a new set of data, we could get completely wrong
  results
\end{itemize}

\hypertarget{seminar-1}{%
\chapter{Seminar 1}\label{seminar-1}}

This seminar is insanely basic. Probably nothing to write down.

\hypertarget{part-week-2}{%
\part{Week 2}\label{part-week-2}}

\hypertarget{regression-part-i}{%
\chapter{Regression part I}\label{regression-part-i}}

\hypertarget{estimation}{%
\section{Estimation}\label{estimation}}

We begin by fitting our data to our standard linear regression model using
\texttt{lm}:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{gm2007 }\OtherTok{\textless{}{-}} \FunctionTok{filter}\NormalTok{(gapminder, year }\SpecialCharTok{==} \DecValTok{2007}\NormalTok{)}
\NormalTok{gm\_lm }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(lifeExp }\SpecialCharTok{\textasciitilde{}}\NormalTok{ gdpPercap, }\AttributeTok{data =}\NormalTok{ gm2007)}
\FunctionTok{print}\NormalTok{(gm\_lm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = lifeExp ~ gdpPercap, data = gm2007)
## 
## Coefficients:
## (Intercept)    gdpPercap  
##   5.957e+01    6.371e-04
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{ggplot}\NormalTok{(gm2007, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ gdpPercap, }\AttributeTok{y =}\NormalTok{ lifeExp)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{"loess"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{st310_files/figure-latex/gapminder-scatter-1.pdf}
\caption{\label{fig:gapminder-scatter}GGPlot point plot}
\end{figure}

\hypertarget{regression-breakdown}{%
\subsection{Regression breakdown}\label{regression-breakdown}}

However, let's break down what the \texttt{lm} function does under the hood. The basic
regression model is:

\begin{equation}
  \hat{\beta}_{1} = \text{cov}(x,y)\dfrac{\sigma_{y}\sigma_{x}}{\sigma_x}
  \label{eq:beta}
\end{equation}

\begin{itemize}
\tightlist
\item
  \(y\) goes in the numerator because if you outcome variable \emph{has a larger
  spread}\footnote{i.e.~a higher standard deviation}, then the slop has to be steeper
\item
  \(x\) is in the denominator because the horizontal axis variance leads to the
  line being less steep
\end{itemize}

We can calculate equation \eqref{eq:beta} by hand in \(R\) as follows\footnote{This is
  also a ``tidyverse way'' of calculating statistics}. First the regular way:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{cor}\NormalTok{(gm2007}\SpecialCharTok{$}\NormalTok{gdpPercap, gm2007}\SpecialCharTok{$}\NormalTok{lifeExp)}
\FunctionTok{sd}\NormalTok{(gm2007}\SpecialCharTok{$}\NormalTok{gdpPercap)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  We see that we have to pass in our column for every summary statistic
\end{itemize}

\texttt{tidyverse} provides function which lets us only pass the data through one and
then essentially makes each column into a variable the function can access.
Basically syntactical sugar:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{summarize}\NormalTok{(gm2007,}
  \AttributeTok{cor\_xy =} \FunctionTok{cor}\NormalTok{(gdpPercap, lifeExp),}
  \AttributeTok{sd\_x =} \FunctionTok{sd}\NormalTok{(gdpPercap),}
  \AttributeTok{sd\_y =} \FunctionTok{sd}\NormalTok{(lifeExp),}
  \AttributeTok{hat\_beta1 =}\NormalTok{ cor\_xy }\SpecialCharTok{*}\NormalTok{ sd\_y }\SpecialCharTok{/}\NormalTok{ sd\_x}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  The usefulness of summarise is that you can do this for any function applied
  to your varaibles is that you can do this for any function applied to your
  varaibles
\item
  \texttt{summarize} basically creates those variables which we passed in as kwargs
\item
  Note that we can just calculate beta there and then within the function using
  the previously defined variables in the call of the function
\item
  \texttt{hat\_beta1} is the same slope as calculated by \texttt{lm}
\end{itemize}

To calculate the intercept, we know that the regression line passes through

\begin{align*}
  (\overline{x},\overline{y})
\end{align*}

\begin{itemize}
\tightlist
\item
  i.e.~the line passes through the point that is the \textbf{mean of the dataset}
\end{itemize}

which means that \(\overline{y}\) is calculated with the estimated slope,
intercept and \(\overline{x}\). So we can rearrange for \(\hat{\beta}_0\):

\begin{equation}
  \begin{aligned}
    \overline{y}&= \hat{\beta}_0 + \hat{\beta}_1 \overline{x}\\
    \hat{\beta}_0&= \overline{y} - \hat{\beta}_1 \overline{x} \label{eq:intercept}
  \end{aligned}
\end{equation}

We can of course do this again with the \texttt{summarise} function:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{summarise}\NormalTok{(gm2007,}
  \AttributeTok{cor\_xy =} \FunctionTok{cor}\NormalTok{(gdpPercap, lifeExp),}
  \AttributeTok{sd\_x =} \FunctionTok{sd}\NormalTok{(gdpPercap),}
  \AttributeTok{sd\_y =} \FunctionTok{sd}\NormalTok{(lifeExp),}
  \AttributeTok{hat\_beta1 =}\NormalTok{ cor\_xy }\SpecialCharTok{*}\NormalTok{ sd\_y }\SpecialCharTok{/}\NormalTok{ sd\_x,}
  \AttributeTok{xbar =} \FunctionTok{mean}\NormalTok{(gdpPercap),}
  \AttributeTok{ybar =} \FunctionTok{mean}\NormalTok{(lifeExp),}
  \AttributeTok{hat\_beta0 =}\NormalTok{ ybar }\SpecialCharTok{{-}}\NormalTok{ hat\_beta1 }\SpecialCharTok{*}\NormalTok{ xbar}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
You should be able to reproduce these basic regression formulas by heart
\end{quote}

We can the give a numerical value of certainty (\(p\)-value) which tells us how
certain we are that our model is correct. This is done by first calculating the
standard errors of the slop \(\hat{\beta}_{1}\):

\begin{equation}
  \begin{aligned}
    \text{SE}(\hat \beta_1) = \sqrt{\frac{\sigma^2}{\sum_{}((x_i - \bar x)^2)}}\\
    \text{se}(\hat \beta_1) = \frac{\hat \sigma}{\sqrt{\sum_{}((x_i - \bar
    x)^2)}}
    \label{eq:se-beta1}
  \end{aligned}
\end{equation}

\begin{itemize}
\tightlist
\item
  The \(\sigma^{2}\) here represents the variance of the \(\epsilon\)s in the model
  which are irreducible
\item
  \textbf{If there is more variance in our errors} then the standard error
  increases\footnote{You can think of this as how far
    away the points are from our regression line}
\item
  The denominator here is the \textbf{how much spread there is in the \(x\) variable}.
  Think of ``how much information there is in the \(x\) variable''. If the \(x\)
  values are all very close to each other \textbf{there is lower variance}\footnote{In this
    instance, information is the recirical of variance here} which means there is
  less information in our \(x\) variable so our standard error increases
\item
  I like to think of it like a standardised proportion of \(\epsilon\) variance
  to how much variance there is in our \(x\) variable\footnote{Like, if there is low
    variance in our \(x\) we would need a low variance in our errors in order for
    the estimated coefficient to be a good predictor}
\end{itemize}

If we look at the summary of the linear model which was produced by
\texttt{R}\footnote{rendered here with the \texttt{tidy} function instead of \texttt{summary} because it
  looks nicer}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{tidy}\NormalTok{(gm\_lm)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  The value we are looking at the estimated coefficients and their standard
  errors. We want to see if we can calcualate, using equation
  \eqref{eq:se-beta1}, the standard error of the estimated coefficient\footnote{In the
    column \texttt{estimate}}
\end{itemize}

We need to estimate \(\sigma^{2}_{\epsilon}\) by using the standard error of the
residuals (RSE)\footnote{This is because the errors are not continuous data and we only
  have a finite number of points so we need an estimator}:

\begin{align}
  \hat \sigma = \text{RSE} = \sqrt{\frac{\text{RSS}}{n-2}}
  \label{eq:rse}
\end{align}

\begin{itemize}
\tightlist
\item
  Where the RSS is the sum of the squared differences between our model fit
  line and the points?
\end{itemize}

We can calculate the RSS via the \texttt{broom} packages function \texttt{augment} which adds
the residual for each element. We can then sum all of those squared residuals
to get RSS to calculate our \(\text{ RSE } = \hat{\sigma}\) using equation
\eqref{eq:rse}:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{augment}\NormalTok{(gm\_lm) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}
    \AttributeTok{RSS =} \FunctionTok{sum}\NormalTok{(.resid}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{), }\CommentTok{\# Summing all the squared residuals}
    \AttributeTok{RSE =} \FunctionTok{sqrt}\NormalTok{(RSS }\SpecialCharTok{/}\NormalTok{ (}\FunctionTok{n}\NormalTok{() }\SpecialCharTok{{-}} \DecValTok{2}\NormalTok{)),}
    \CommentTok{\# Calculating standar error}
    \AttributeTok{std.err =}\NormalTok{ RSE }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{((gdpPercap }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(gdpPercap))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  The function \texttt{n} here calculates the sample size of our group
\end{itemize}

\hypertarget{regressing-over-the-whole-dataset-and-not-just-the-gm2007-subset-using-group_by}{%
\subsection{\texorpdfstring{Regressing over the whole dataset and not just the \texttt{gm2007} subset using \texttt{group\_by}}{Regressing over the whole dataset and not just the gm2007 subset using group\_by}}\label{regressing-over-the-whole-dataset-and-not-just-the-gm2007-subset-using-group_by}}

We can use the entire dataset and \textbf{group by a given variable} with the
following:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{gapminder }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(year) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}
    \AttributeTok{cor\_xy =} \FunctionTok{cor}\NormalTok{(gdpPercap, lifeExp),}
    \AttributeTok{sd\_x =} \FunctionTok{sd}\NormalTok{(gdpPercap),}
    \AttributeTok{sd\_y =} \FunctionTok{sd}\NormalTok{(lifeExp),}
    \AttributeTok{hat\_beta1 =}\NormalTok{ cor\_xy }\SpecialCharTok{*}\NormalTok{ sd\_y }\SpecialCharTok{/}\NormalTok{ sd\_x,}
    \AttributeTok{xbar =} \FunctionTok{mean}\NormalTok{(gdpPercap),}
    \AttributeTok{ybar =} \FunctionTok{mean}\NormalTok{(lifeExp),}
    \AttributeTok{hat\_beta0 =}\NormalTok{ ybar }\SpecialCharTok{{-}}\NormalTok{ hat\_beta1 }\SpecialCharTok{*}\NormalTok{ xbar}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}\AttributeTok{booktabs =}\NormalTok{ T)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{rrrrrrrr}
\toprule
year & cor\_xy & sd\_x & sd\_y & hat\_beta1 & xbar & ybar & hat\_beta0\\
\midrule
1952 & 0.2780236 & 9321.065 & 12.22596 & 0.0003647 & 3725.276 & 49.05762 & 47.69913\\
1957 & 0.3037445 & 9869.662 & 12.23129 & 0.0003764 & 4299.408 & 51.50740 & 49.88900\\
1962 & 0.3832211 & 8667.363 & 12.09724 & 0.0005349 & 4725.812 & 53.60925 & 51.08155\\
1967 & 0.4801398 & 8095.315 & 11.71886 & 0.0006951 & 5483.653 & 55.67829 & 51.86685\\
1972 & 0.4597014 & 10614.383 & 11.38195 & 0.0004929 & 6770.083 & 57.64739 & 54.31011\\
\addlinespace
1977 & 0.6198638 & 8362.489 & 11.22723 & 0.0008322 & 7313.166 & 59.57016 & 53.48406\\
1982 & 0.7227629 & 7733.845 & 10.77062 & 0.0010066 & 7518.902 & 61.53320 & 53.96495\\
1987 & 0.7499054 & 8288.281 & 10.55629 & 0.0009551 & 7900.920 & 63.21261 & 55.66637\\
1992 & 0.7047148 & 9031.846 & 11.22738 & 0.0008760 & 8158.609 & 64.16034 & 57.01321\\
1997 & 0.7036436 & 10171.493 & 11.55944 & 0.0007997 & 9090.175 & 65.01468 & 57.74564\\
\addlinespace
2002 & 0.6818578 & 11154.115 & 12.27982 & 0.0007507 & 9917.848 & 65.69492 & 58.24986\\
2007 & 0.6786624 & 12859.937 & 12.07302 & 0.0006371 & 11680.072 & 67.00742 & 59.56565\\
\bottomrule
\end{tabular}

\begin{itemize}
\tightlist
\item
  \texttt{group\_by} basically slices and dices our dataset into the group we provide
  and then the summarise allows us to run the summary statistics on each one of
  those groups
\item
  The output here shows us the \texttt{hat\_beta1} isn't very stable over time
\end{itemize}

\hypertarget{model-diagnostics}{%
\section{Model diagnostics}\label{model-diagnostics}}

Diagnostics for regression include \(R^{2}\) and the RSE.

\hypertarget{r2}{%
\subsection{\texorpdfstring{\(R^{2}\)}{R\^{}\{2\}}}\label{r2}}

\hypertarget{simple-linear-regression-r2}{%
\subsubsection{\texorpdfstring{Simple linear regression \(R^{2}\)}{Simple linear regression R\^{}\{2\}}}\label{simple-linear-regression-r2}}

The \texttt{glance} function from the \texttt{broom} package outputs the \(R^{2}\) and adjusted
\(R^{2}\) for a model:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{glance}\NormalTok{(gm\_lm)}
\end{Highlighting}
\end{Shaded}

If we want to calculate this ourself, we need to use the \(R^{2}\) calculation
for a SIMPLE linear regression\footnote{One intercept and one dependent variable:
  \(Y=\beta_0+beta_1x_1\)} which is:

\begin{align*}
  R^{2} = \text{cor}(x,y)^{2}
\end{align*}

\begin{itemize}
\tightlist
\item
  I.e. it's just the correlation of our two variables squared. This is only in
  the case of a SIMPLE REGRESSION
\end{itemize}

We can easily calculate this with \texttt{R}:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{cor}\NormalTok{(gm2007}\SpecialCharTok{$}\NormalTok{gdpPercap, gm2007}\SpecialCharTok{$}\NormalTok{lifeExp)}\SpecialCharTok{\^{}}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\hypertarget{general-linear-regression-r2}{%
\subsubsection{\texorpdfstring{General linear regression \(R^{2}\)}{General linear regression R\^{}\{2\}}}\label{general-linear-regression-r2}}

The general formula for \(R^{2}\) is:

\begin{align}
  R^{2} = 1 - \dfrac{RSS}{TSS}
\end{align}

\begin{itemize}
\tightlist
\item
  That is, \(R^{2}\) is the proportion of the RSS to the TSS\footnote{Total sum of
    squares}.
\end{itemize}

\begin{quote}
We commonly call this the explanation power of our model. It is the
proportion of our sum of squares of residuals to the total sum of squares of
our \(Y\) variable, i.e.~all the values less their means (i.e.~the ``centred''
values) squared and the summed up

\begin{align*}
TSS = \sum(y - \overline{y})^{2})
\end{align*}
\end{quote}

In \texttt{R} we can just calculate this with \texttt{tidyverse::augment}\footnote{Giving us the
  residuals} and \texttt{summarise}:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{augment}\NormalTok{(gm\_lm) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}
    \AttributeTok{RSS =} \FunctionTok{sum}\NormalTok{(.resid}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{),}
    \AttributeTok{TSS =} \FunctionTok{sum}\NormalTok{((lifeExp }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(lifeExp))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{),}
    \AttributeTok{R2 =} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ RSS }\SpecialCharTok{/}\NormalTok{ TSS}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\hypertarget{pattern-searching-in-residuals}{%
\subsection{Pattern searching in residuals}\label{pattern-searching-in-residuals}}

We want to look for patterns in residuals because of variance-bias
decomposition from equation \eqref{eq:bias-var-to}. We have parts of errors that
are systematic (bias) and idiosyncratic (variance). In any given problem there
is inherent variability but we should be controlling for as much bias as
possible. We do this by \emph{looking for pattern in the residuals} as systemic
errors can show up in residuals.

Let's plot the residuals to see if we notice anything:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{augment}\NormalTok{(gm\_lm) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(gdpPercap, .resid)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{st310_files/figure-latex/unnamed-chunk-36-1.pdf}

\begin{itemize}
\tightlist
\item
  This plot shows the residuals for the
\item
  This plot can show us some serious problems we can see that there is \textbf{one
  large cluster of points on the left side and a trend} on the left side of
  the plot which clearly has a downward sloping trend. The residual are
  becoming more negative as \texttt{gdpPercap} increases.
\end{itemize}

\begin{quote}
REMINDER: residuals are the DIFFERENCE between the actual values, and the
values our model spits out. I.e. the distance of the points from the line of
best fit. Because our line is essentially a continuous set of points.
\end{quote}

\hypertarget{history-of-least-squares}{%
\chapter{History of least squares}\label{history-of-least-squares}}

\hypertarget{og-constraint}{%
\section{A constraint we can place when fitting a line}\label{og-constraint}}

\begin{quote}
This exercise shows us that the sum of the residuals is 0 \(\iff\) the line
passes through the point with the average value of \texttt{x} and the average value
of \(y\)
\end{quote}

Suppose \((x_i, y_i)\) are observations we wish to model as

\begin{align*}
y_{i} = \alpha + \beta x_{i} + \epsilon_{i}
\end{align*}

for some unknown optimal values of \((\alpha,\beta)\).\\
For a given choice \((\hat{\alpha})\) let \(\hat{y}_{i} = \hat{\alpha} + \hat{\beta}x_{i}\) and \(r_{i} = y_{i} - \hat{y}_{i}\)

\textbf{Exercise/constraint}: Show that \(\bar r = 0\) if and only if the line \(y = \hat \alpha + \hat \beta x\) passes through the point \((\bar x, \bar y)\).

\textbf{Problem}: There are (uncountably) infinitely many solutions with ``zero
average error''

For a given \(x \neq \bar x\), could predict \emph{any} \(y\) with one of these lines.
Any line that passes through this point satisfies this particular constraint
and can predict any value of \(y\) given a value of \(x\). This is not what we
want.

\hypertarget{constraints-and-constrained-methods}{%
\section{Constraints and constrained methods}\label{constraints-and-constrained-methods}}

If the method is mathematically well-defined, producing a unique solution, then
theories formed using that method can be severely tested\footnote{We want a well
  defined problem so we can produce a single solution. This is why flexible
  models are more difficult to disprove/say there is something absolutely
  incorrect with the model}.

So we will add some additional constraints to our original constraint of
passing through \((\overline{x},\overline{y})\):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The errors sum to 0
\end{enumerate}

\hypertarget{why-squared-errors}{%
\subsection{Why squared errors}\label{why-squared-errors}}

Of all the alternative measures you could try and minimise, the least squares
is the \textbf{most simple}. The other minimisations would lead to very difficult
computations. It is almost tradition to use least squares because it was the
only one remotely computable by hand back in the day.

Another reason we like to use least squares is because it has convenient
geometry.

We want to minimise the residuals because we want to show that the sum of the
residuals is 0 (from the \protect\hyperlink{og-constraint}{original constraint}). We know from
\eqref{eq:regression-intercept} that we can rearrange for the residuals in terms
of \(\beta_{0}\)\footnote{Here, and often, denoted as \(\alpha\)}, \(\beta_{1}\), and \(y\).
So, at a minimum of\footnote{This is an objective function as a function of the
  intercept and slope that we are going to fit. pretty sure the \(l\) is merely
  notation name like calling a function \(f\)}:

\begin{align}
  \ell (\hat{\alpha}, \hat{\beta}) = \sum_i (y_i - \hat{\alpha} - \hat{\beta}
  x_i)^2 \label{eq:min-squared-errors}
\end{align}

Taking the partial derivatives\footnote{A reminder that we set the variable that isn't
  in the denominator of the differentiation notation to 0}:

\begin{align*}
  0&= \frac{\partial \ell}{\partial \alpha} = 2 \sum_i r_i\\
  0&= \frac{\partial\ell}{\partial\beta} = 2 \sum_i x_i r_i
\end{align*}

\begin{itemize}
\tightlist
\item
  We see that we have that the sum of residuals is equal to 0
\item
  We thus have \textbf{orthogonality}
\end{itemize}

(\textbf{Orthogonality, uncorrelatedness, bias}). Since \(\overline{r} = 0\) and \(\sum x_{i}r_{i} = 0\), we also have:

\begin{align*}
  \text{cor}(x,y) = 0
\end{align*}

\begin{itemize}
\tightlist
\item
  Correlation measures \textbf{\emph{linear independence}}.
\item
  If we minimised a different loss function\footnote{The name of a function that
    calculates residuals, i.e.~the difference between the output of our algorithm
    when given the real data point and the expected output (where the data point
    actually is)} and the resulting residuals were correlated with \(x\), this
  would mean there is some remaining (linear) signal, i.e.~we still have some
  bias
\end{itemize}

\begin{quote}
Minimising the squared error rules out the systematic bias. As long as we
minimise the squared error, we will be effectively eliminating bias.
\end{quote}

\hypertarget{risk-probability-and-loss}{%
\section{Risk: probability and loss}\label{risk-probability-and-loss}}

\hypertarget{randomness-and-probability-models}{%
\subsection{Randomness and probability models}\label{randomness-and-probability-models}}

So far we have minimised the squared error on \emph{observed data} (equation
\eqref{eq:min-squared-errors}). If we can introduce a probability model to our
data, some joint distribution \(p_{X,Y}(x,y)\) then we can minimise:

\begin{equation}
  \min \mathbb{E}[(Y - \alpha - \beta X)^{2}] \label{eq:ese}
\end{equation}

i.e.~minimise the expected squared error because we have made assumptions about
the probability distribution.

\hypertarget{generative-ml}{%
\subsection[Generative ML]{\texorpdfstring{Generative ML\footnote{We will mainly focus on these in this course}}{Generative ML}}\label{generative-ml}}

\begin{itemize}
\tightlist
\item
  Models that use probability distributions in machine learning are sometimes
  known as ``generative'' models beacause they:

  \begin{itemize}
  \tightlist
  \item
    Model the ``data generation pricess'' (DGP)
  \item
    Can be used to generate synthetic data
  \end{itemize}
\end{itemize}

\hypertarget{conditional-distributions}{%
\subsection{Conditional distributions}\label{conditional-distributions}}

Supervised learning is mostly about modelling the conditional distribution of
the given outcome variable with the feature variables:

\begin{align*}
  p_{Y|X}(y|x) =  p_{X,Y}(x,y) / p_{X}(x)
\end{align*}

Some ML methods try to learn the entire distribution and others focus on a
summary like conditional expectation/conditional quantile:

\begin{align}
  &\text{ conditional expectation } = \mathbb{E}_{Y|X}[Y|X] \label{eq:cef}\\
  &\text{ conditional quantile } = Q_{Y|X}(\pi) \notag
\end{align}

You can visualise conditional distribution on the actual data plot using curves
showing \(p_{Y|X}(y|x)\) at two values of \(x\) by fixing some value on the
horizontal axis (i.e.~this is what is given) and then looking at a probability
distribution above the point on the line of the vertical axis (figure
\ref{fig:visual-conditional-prob}).

\begin{itemize}
\tightlist
\item
  We can also see the difference between trying to understand the whole
  probability distribution vs just trying to compute a conditional
  distribution. I.e. the regression line gives us one number for any \(x\)\footnote{i.e.
    \(\mathbb{E}_{Y|X}[Y|X]\)} but not the distribution around that number, i.e.
  the entire conditional probability distribution.
\end{itemize}

\hypertarget{conditional-expectation-and-minimisation-of-expected-squared-loss}{%
\subsection{Conditional expectation and minimisation of expected squared loss}\label{conditional-expectation-and-minimisation-of-expected-squared-loss}}

It can be shown that the conditional expectation function (CEF, \eqref{eq:cef})
minimises the expected squared loss:

\begin{align*}
  f(x) = \text{arg}\underset{g}\min \mathbb{E}_{X,Y}\{ [ Y - g(X) ]^2 \}
\end{align*}

\begin{itemize}
\tightlist
\item
  So, out of all possible functions of \(x\)\footnote{Provided that it is measurable and
    integerable}, the one that \textbf{square error in predicting \(y\)} is the
  conditional expectation of \(y\) conditional on \(x\).
\end{itemize}

Similarly, \textbf{quantile regression} on the 50\% quantile, that loss function is
just the absolute of the loss function:

\begin{align*}
  Q_{Y|X}(0.5) = \arg \min_g \mathbb E_{X,Y} [ |Y - g(X)| ]
\end{align*}

\begin{quote}
For other quantiles you must take the absolute loss function and you have to
tilt it
\end{quote}

\hypertarget{quesitons}{%
\chapter{Quesitons}\label{quesitons}}

\begin{itemize}
\tightlist
\item
  Where the RSS is the sum of the squared differences between our model fit
  line and the points? \eqref{eq:rse}
\item
  What the hell is going on in \ref{why-squared-errors}. In terms of
  orthogonality
\end{itemize}

\hypertarget{r-notes}{%
\chapter[\texttt{R} notes]{\texorpdfstring{\texttt{R} notes\footnote{These are probably temporary and will go into own book}}{R notes}}\label{r-notes}}

\begin{quote}
This is the more general stuff that isn't categorisable into the lecture
work. For specific \texttt{R} functions just look at the coursework in the root
directory of the course
\end{quote}

\hypertarget{using-the-r-repl}{%
\section{\texorpdfstring{Using the \texttt{R} repl}{Using the R repl}}\label{using-the-r-repl}}

To use the \texttt{R} repl, you just

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\ExtensionTok{R}
\end{Highlighting}
\end{Shaded}

type \texttt{R} on the command line. This launches the \texttt{R} repl and you can write any
code you want. I.e. when you want to install a package, you can use the repl

\hypertarget{managing-packages}{%
\section{Managing packages}\label{managing-packages}}

To install a package in \texttt{R}, you use the install object:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{install.packages}\NormalTok{(\{}
\NormalTok{  package}\SpecialCharTok{:}\NormalTok{string}
\NormalTok{\})}

\CommentTok{\# For example installing renv for virtual environments}
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"renv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  You pass the name of your package as the argument as a string
\end{itemize}

\hypertarget{r-virtual-environments}{%
\section{\texorpdfstring{\texttt{R} virtual environments}{R virtual environments}}\label{r-virtual-environments}}

You don't want global packages everywhere, some of them will only be useful for
particular projects. Queue \texttt{renv}, the \texttt{R} virtual environment manager.

To create a virtualenv, go into the root of your project directory and run

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{renv}\SpecialCharTok{::}\FunctionTok{init}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

to initialise your virtual environment.

\begin{itemize}
\tightlist
\item
  You should create your \texttt{.gitignore\ .Rbuildignore}, and \texttt{.Rprofile} files
  before running this because it auto updates them
\end{itemize}

You can then install packages as usual and once you have completed your
project, you can use \texttt{renv::snapshow()} to write the dependencies to the
\texttt{renv.lcok} file.\footnote{Note that this only writes the libraries you call in your
  code. So without a project, you will not have any dependencies}

\hypertarget{lsp-in-virtual-environments}{%
\subsection{LSP in virtual environments}\label{lsp-in-virtual-environments}}

Just spent ages trying to figure out why my LSP wasn't picking up my
virtualenv. It was because the \texttt{R} package \texttt{languageserver} must be installed
in the virtualenv in order for neovim to find the script to execute.

LSP has:

\begin{itemize}
\tightlist
\item
  Formatting
\item
  Completion
\end{itemize}

\hypertarget{loading-with-the-library-command}{%
\section{Loading with the library command}\label{loading-with-the-library-command}}

Note: in \ref{r-virtual-environments} we preface the \texttt{init()} command with \texttt{renv::} denoting that we want
to use the \texttt{init()} command from that specific package. If we were running a
command constantly, we could use:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{library}\NormalTok{(renv)}
\FunctionTok{init}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

to \textbf{bring all the function from the \texttt{renv} package into our environment's
scope}.

\hypertarget{environemnt-variables}{%
\section{Environemnt variables}\label{environemnt-variables}}

You can get and set environemnt variables with:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{Sys.getenv}\NormalTok{()}
\FunctionTok{Sys.setenv}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

To remove an envrionement variable you can use:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{Sys.unsetenv}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{viewing-r-documentation}{%
\section{\texorpdfstring{Viewing \texttt{R} documentation}{Viewing R documentation}}\label{viewing-r-documentation}}

In \texttt{R}, if you want any documentation, you just need to preface the command
with a question mark:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{?install}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Note that we don't call the function when we ask for help
\end{itemize}

\hypertarget{the-select-function}{%
\section{\texorpdfstring{The \texttt{select} function}{The select function}}\label{the-select-function}}

You can use the \texttt{select} function to select/deselect rows from your model:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{subset }\OtherTok{\textless{}{-}} \FunctionTok{select}\NormalTok{(my\_data, }\SpecialCharTok{{-}}\StringTok{"name of column"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{indexing-in-r}{%
\section{\texorpdfstring{Indexing in \texttt{R}}{Indexing in R}}\label{indexing-in-r}}

Indexing in \texttt{R} is pretty similar to something like \texttt{pandas}. If I have a
dataset I can index it in one of two way. The first:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{myplot[}\DecValTok{5}\NormalTok{, ]}
\NormalTok{myplot[, }\DecValTok{5}\NormalTok{]}
\NormalTok{myplot[}\DecValTok{2}\NormalTok{, }\DecValTok{5}\NormalTok{]}
\NormalTok{myplot[}\DecValTok{2}\SpecialCharTok{:}\DecValTok{4}\NormalTok{, }\DecValTok{5}\SpecialCharTok{:}\DecValTok{7}\NormalTok{]}
\NormalTok{myplot[myplot[, }\DecValTok{5}\NormalTok{] }\SpecialCharTok{==} \DecValTok{7}\NormalTok{, }\DecValTok{5}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Line 1 returns row 5 and all columns
\item
  Line 2 returns column 5 with all rows
\item
  Line 3 returns cell from column 5 row 2
\item
  Line 4 returns the cells in rows 2 to 4 and columns 5 to 7\footnote{Not sure if it's
    inclusive or not}
\item
  Line 5 return the rows in column 5 which have a value of 7
\end{itemize}

\begin{quote}
Data indexing in \texttt{R} is always {[}, {]}
\end{quote}

The second way is with the \texttt{\$} operator:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{mydata[mydata}\SpecialCharTok{$}\NormalTok{year }\SpecialCharTok{==} \DecValTok{2020}\NormalTok{, ]}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  This will return all columns for the rows that contain 2020
\end{itemize}

\hypertarget{the-tidyverse-way-of-indexing}{%
\subsection{\texorpdfstring{The \texttt{tidyverse} way of indexing}{The tidyverse way of indexing}}\label{the-tidyverse-way-of-indexing}}

This is quite a javascript way of doing things. We use the \texttt{filter} function,
much like you would use it in js

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{filter}\NormalTok{(dataset, }\FunctionTok{c}\NormalTok{(year }\SpecialCharTok{==} \DecValTok{2000}\NormalTok{, continent }\SpecialCharTok{==} \StringTok{"Asia"}\NormalTok{, ...))}
\end{Highlighting}
\end{Shaded}

\hypertarget{miscellaneous-tips}{%
\section{Miscellaneous tips}\label{miscellaneous-tips}}

\hypertarget{viewing-your-dataset-in-a-spreadsheet-like-manner}{%
\subsection{Viewing your dataset in a spreadsheet-like manner}\label{viewing-your-dataset-in-a-spreadsheet-like-manner}}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{View}\NormalTok{(}\SpecialCharTok{\textless{}}\NormalTok{dataset}\SpecialCharTok{\textgreater{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{generating-a-polynomial}{%
\subsection{Generating a polynomial}\label{generating-a-polynomial}}

You can generate a polynomical using:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{poly}\NormalTok{(\{datacolumn\}, \{polynomial degree\})}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  This will basically plot a standard polynomial for the \texttt{x} data values
  (vector?) that you pass as an arg.
\end{itemize}

\hypertarget{adding-cols-onto-a-dataframe}{%
\subsection{Adding cols onto a dataframe}\label{adding-cols-onto-a-dataframe}}

You can use \texttt{augment} to add columns onto a dataframe

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{augment}\NormalTok{(my\_df, }\AttributeTok{newdata =}\NormalTok{ newdf)}
\end{Highlighting}
\end{Shaded}

\hypertarget{including-all-variables-in-your-model}{%
\subsection{Including all variables in your model}\label{including-all-variables-in-your-model}}

The shorthand to inlcude all the variables in your dataset in your model is:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ my\_data)}
\end{Highlighting}
\end{Shaded}

What you need to avoid here though is using a variable which is unique to every
piece of data, like brand, etc.

\end{document}
